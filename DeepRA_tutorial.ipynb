{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoLoUZ-LjUsK"
      },
      "source": [
        "# **Tutorial for using DeepRA framework in mutagenicity prediction**\n",
        "## DeepRA: A Novel Deep Learning-Read-Across Framework and Its Application in Non-Sugar Sweeteners Mutagenicity Prediction\n",
        "Tarapong Srisongkram\n",
        "* Division of Pharmaceutical Chemistry, Faculty of Pharmaceutical Sciences, Khon Kaen University, 40002 (tarasri@kku.ac.th)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG3FBqwQj-ue"
      },
      "source": [
        "To use this model, please use our sweeteners csv template and change our data to your data, **without changing the column names.**\n",
        "* **This software requires only chemical name and canonical SMILES**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s783u5l_l3f7"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Download models\n",
        "from joblib import load\n",
        "#scaler_mord = load('mordred_scaler.joblib')\n",
        "model_mord  = load('CNN-Mordred.joblib')\n",
        "model_rdkit = load('CNN-RDKIT.joblib')\n",
        "model_ecfp  = load('CNN-ECFP.joblib')\n",
        "model_ad    = load('AD_nn.joblib')\n",
        "deepra      = load('DeepRA-Mordred.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ttwr6q6kogC9",
        "outputId": "8a989831-25f3-4e0b-e784-459cb4c215e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>canonical_smiles</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dulcin</th>\n",
              "      <td>CCOc1ccc(NC(N)=O)cc1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            canonical_smiles\n",
              "Name                        \n",
              "dulcin  CCOc1ccc(NC(N)=O)cc1"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load test data\n",
        "import pandas as pd\n",
        "df = pd.read_csv('dulcin.csv', index_col = 'Name')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGDlX2XjpDa7",
        "outputId": "8cef6777-0874-4652-af8a-96698acb827e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
          ]
        }
      ],
      "source": [
        "#Calculate Mordred, ECFP, RDKIT\n",
        "from mordred import Calculator, descriptors\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem as Chem\n",
        "\n",
        "def morded_cal(df, smiles_col):\n",
        "    #calculate descriptors\n",
        "    calc = Calculator(descriptors, ignore_3D=True)\n",
        "    mols = [Chem.MolFromSmiles(smi) for smi in df[smiles_col]]\n",
        "    des = calc.pandas(mols)\n",
        "    des = des.set_index(df.index)\n",
        "    with open('mordreds.txt', 'r') as file:\n",
        "      columns = [line.strip() for line in file]\n",
        "    selected_mord = des[columns]\n",
        "    selected_mord\n",
        "    return selected_mord\n",
        "def calculate_ecfp(df, smiles_col, radius=10, nBits=4096):\n",
        "    def get_ecfp(smiles):\n",
        "        try:\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            fingerprint = Chem.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n",
        "            return [int(bit) for bit in fingerprint.ToBitString()]\n",
        "        except:\n",
        "            return [None] * nBits  # Return a list of None if an error occurs\n",
        "\n",
        "    ecfp_bits_df = df[smiles_col].apply(get_ecfp).apply(pd.Series)\n",
        "    ecfp_bits_df.columns = [f'ECFP{i}' for i in range(nBits)]\n",
        "    df = pd.concat([df, ecfp_bits_df], axis=1)\n",
        "\n",
        "    return df\n",
        "def calculate_rdkit(df, smiles_col, nBits=2048):\n",
        "    def get_ecfp(smiles):\n",
        "        try:\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            fingerprint = Chem.RDKFingerprint(mol)\n",
        "            return [int(bit) for bit in fingerprint.ToBitString()]\n",
        "        except:\n",
        "            return [None] * nBits  # Return a list of None if an error occurs\n",
        "\n",
        "    rdkit_bits_df = df[smiles_col].apply(get_ecfp).apply(pd.Series)\n",
        "    rdkit_bits_df.columns = [f'RDKit{i}' for i in range(nBits)]\n",
        "    df = pd.concat([df, rdkit_bits_df], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "df_mord = morded_cal(df, 'canonical_smiles')\n",
        "df_ecfp = calculate_ecfp(df, 'canonical_smiles')\n",
        "df_rdkit= calculate_rdkit(df, 'canonical_smiles')\n",
        "\n",
        "df_ecfp = df_ecfp.drop(['canonical_smiles'],axis=1)\n",
        "df_rdkit = df_rdkit.drop(['canonical_smiles'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Du1yxOrNWH",
        "outputId": "5c0f6062-8605-4f5a-b2f6-f1f126988107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "        CNN-Mordred\n",
            "Name               \n",
            "dulcin            0\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "        CNN-ECFP\n",
            "Name            \n",
            "dulcin         1\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "        CNN-RDKIT\n",
            "Name             \n",
            "dulcin          1\n"
          ]
        }
      ],
      "source": [
        "#Compute baseline CNN\n",
        "import numpy as np\n",
        "#Mord\n",
        "name = 'CNN-Mordred'\n",
        "scaler_mord = load('mordred_scaler.joblib')\n",
        "x_mord_np = scaler_mord.transform(df_mord)\n",
        "y_predict_cnn_mord = model_mord.predict(x_mord_np)\n",
        "y_predict_cnn_mord = np.where(y_predict_cnn_mord > 0.5 ,1 ,0)\n",
        "y_predict_cnn_mord = pd.DataFrame(y_predict_cnn_mord, columns=[name]).set_index(df_mord.index)\n",
        "print(y_predict_cnn_mord)\n",
        "#ECFP\n",
        "name = 'CNN-ECFP'\n",
        "x_ecfp_np = np.array(df_ecfp)\n",
        "y_predict_cnn_ecfp = model_ecfp.predict(x_ecfp_np)\n",
        "y_predict_cnn_ecfp = np.where(y_predict_cnn_ecfp > 0.5 ,1 ,0)\n",
        "y_predict_cnn_ecfp = pd.DataFrame(y_predict_cnn_ecfp, columns=[name]).set_index(df_ecfp.index)\n",
        "print(y_predict_cnn_ecfp)\n",
        "#RDKIT\n",
        "name = 'CNN-RDKIT'\n",
        "x_rdkit_np  = np.array(df_rdkit)\n",
        "y_predict_cnn_rdkit = model_rdkit.predict(x_rdkit_np)\n",
        "y_predict_cnn_rdkit = np.where(y_predict_cnn_rdkit > 0.5 ,1 ,0)\n",
        "y_predict_cnn_rdkit = pd.DataFrame(y_predict_cnn_rdkit, columns=[name]).set_index(df_rdkit.index)\n",
        "print(y_predict_cnn_rdkit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8sFdd8GrRA4",
        "outputId": "2f58a933-4721-4c60-e548-52ece0e9ec72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1]\n",
            "        ra_ecfp\n",
            "Name           \n",
            "dulcin        1\n",
            "[1 1 1]\n",
            "        ra_rdkit\n",
            "Name            \n",
            "dulcin         1\n"
          ]
        }
      ],
      "source": [
        "#Compute baseline RA\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "train = pd.read_csv('train.csv', index_col='PubChem CID')\n",
        "y_train = train['Toxicity Value']\n",
        "def ra_ecfp(train,test, y_train, n_top, smiles_col,weight_power, nBits=4096):\n",
        "    y_pred = []\n",
        "    #smiles to morgan fingerprint\n",
        "    train_smile= list(train[smiles_col])\n",
        "    test_smile = list(test[smiles_col])\n",
        "    for compound_test in test_smile:\n",
        "        mol1 = Chem.MolFromSmiles(compound_test)\n",
        "        fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 8, nBits=4096)\n",
        "        similarity_array = []\n",
        "        for compound_train in train_smile:\n",
        "            mol2 = Chem.MolFromSmiles(compound_train)\n",
        "            fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 8, nBits=4096)\n",
        "            similarity = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
        "            similarity_array.append(similarity)\n",
        "        similarity_series = pd.Series(similarity_array, index = train.index)\n",
        "        adjusted_weights = similarity_series ** weight_power\n",
        "        indices = similarity_series.nlargest(n_top).index\n",
        "        y_values = y_train.loc[indices].values.flatten()  # make sure y_values is 1D\n",
        "        print(y_values)\n",
        "        y_pred.append(np.average(y_values, weights=adjusted_weights.loc[indices].values))\n",
        "    y_pred = pd.DataFrame(y_pred, index=test.index, columns=['ra_ecfp'])\n",
        "    #set threshold to 0.5\n",
        "    y_pred['ra_ecfp'] = y_pred['ra_ecfp'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
        "    return y_pred\n",
        "\n",
        "y_predict_ra_ecfp = ra_ecfp(train, df, y_train, 3, 'canonical_smiles', 1, nBits=4098)\n",
        "print(y_predict_ra_ecfp)\n",
        "\n",
        "\n",
        "def ra_rdkit(train,test, y_train, n_top, smiles_col,weight_power):\n",
        "    from rdkit import Chem, DataStructs\n",
        "    from rdkit.Chem import AllChem\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    y_pred = []\n",
        "    #smiles to morgan fingerprint\n",
        "    train_smile= list(train[smiles_col])\n",
        "    test_smile = list(test[smiles_col])\n",
        "    for compound_test in test_smile:\n",
        "        mol1 = Chem.MolFromSmiles(compound_test)\n",
        "        fp1 = Chem.RDKFingerprint(mol1)\n",
        "        similarity_array = []\n",
        "        for compound_train in train_smile:\n",
        "            mol2 = Chem.MolFromSmiles(compound_train)\n",
        "            fp2 = Chem.RDKFingerprint(mol2)\n",
        "            similarity = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
        "            similarity_array.append(similarity)\n",
        "        similarity_series = pd.Series(similarity_array, index = train.index)\n",
        "        adjusted_weights = similarity_series ** weight_power\n",
        "        indices = similarity_series.nlargest(n_top).index\n",
        "        y_values = y_train.loc[indices].values.flatten()  # make sure y_values is 1D\n",
        "        print(y_values)\n",
        "        y_pred.append(np.average(y_values, weights=adjusted_weights.loc[indices].values))\n",
        "    y_pred = pd.DataFrame(y_pred, index=test.index, columns=['ra_rdkit'])\n",
        "    #set threshold to 0.5\n",
        "    y_pred['ra_rdkit'] = y_pred['ra_rdkit'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
        "    return y_pred\n",
        "y_predict_ra_rdkit = ra_rdkit(train, df, y_train, 3, 'canonical_smiles',1)\n",
        "print(y_predict_ra_rdkit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "9CTGuoGYrT52",
        "outputId": "a156d65d-57c9-477f-dbdd-7038ce194be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                      ABC  \\\n",
            "Name                                                        \n",
            "dulcin  module 'numpy' has no attribute 'float'.\\n`np....   \n",
            "\n",
            "                                                    ABCGG  nAcid  nBase  \\\n",
            "Name                                                                      \n",
            "dulcin  module 'numpy' has no attribute 'float'.\\n`np....      0      0   \n",
            "\n",
            "          SpAbs_A   SpMax_A  SpDiam_A     SpAD_A   SpMAD_A  LogEE_A  ...  \\\n",
            "Name                                                                 ...   \n",
            "dulcin  15.809802  2.241795   4.48359  15.809802  1.216139  3.44374  ...   \n",
            "\n",
            "        WPol  Zagreb1  Zagreb2  mZagreb1  mZagreb2  ra_ecfp  ra_rdkit  \\\n",
            "Name                                                                    \n",
            "dulcin    14     58.0     62.0  5.083333  3.083333        1         1   \n",
            "\n",
            "        CNN-ECFP  CNN-RDKIT  CNN-Mordred  \n",
            "Name                                      \n",
            "dulcin         1          1            0  \n",
            "\n",
            "[1 rows x 978 columns]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-8b0b22b306a2>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscaler_deepra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DeepRA-Mordred-scaler.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx_deepra\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mscaler_deepra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_deepra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_predict_deepra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_deepra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 )\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     def _validate_data(\n",
            "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
          ]
        }
      ],
      "source": [
        "#Compute DeepRA\n",
        "name = 'DeepRA-Mordred'\n",
        "#Mordred + CNN-Mord + CNN-ECFP + CNN-RDKIT + RA-ECFP + RA-RDKIT\n",
        "x_te   = pd.concat([df_mord, y_predict_ra_ecfp, y_predict_ra_rdkit, y_predict_cnn_ecfp, y_predict_cnn_rdkit, y_predict_cnn_mord], axis=1)\n",
        "print(x_te)\n",
        "# Transform the test data using the scaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from joblib import load\n",
        "scaler_deepra = load('DeepRA-Mordred-scaler.joblib')\n",
        "x_deepra  = scaler_deepra.transform(x_te)\n",
        "print(x_deepra)\n",
        "y_predict_deepra = deepra.predict(x_deepra)\n",
        "y_predict_deepra_class = np.where(y_predict_deepra > 0.5 ,1 ,0)\n",
        "y_predict_deepra = pd.DataFrame(y_predict_deepra, columns=[name]).set_index(df.index)\n",
        "y_predict_deepra_class = pd.DataFrame(y_predict_deepra_class, columns=['class']).set_index(df.index)\n",
        "y_predict_deepra_class = pd.concat([y_predict_deepra, y_predict_deepra_class], axis=1)\n",
        "y_predict_deepra_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "I43yW7VRrW3w",
        "outputId": "36b51d9f-ce5d-43ae-9039-5a9d0abff97b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8fab81ea0a16>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAD_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AD_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtest_ad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnearest_neighbor_AD_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_deepra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mtest_ad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-8fab81ea0a16>\u001b[0m in \u001b[0;36mnearest_neighbor_AD_predict\u001b[0;34m(x_te, x_test, k, z)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AD_nn.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#calculate mean and sd of distance in train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ],
      "source": [
        "#Compute Applicability Domain\n",
        "def nearest_neighbor_AD_predict(x_te, x_test, k, z=0.5):\n",
        "    from joblib import load\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    nn = load('AD_nn.joblib')\n",
        "    distance, index = nn.kneighbors(x_test)\n",
        "    #calculate mean and sd of distance in train set\n",
        "    di = np.mean(distance, axis = 1)\n",
        "    dk =  1.004\n",
        "    sk =  0.489\n",
        "    print('dk = ', dk)\n",
        "    print('sk = ', sk)\n",
        "    AD_status = []\n",
        "    for i in range(len(di)):\n",
        "        if di[i] < dk + (z * sk):\n",
        "            AD_status.append('within_AD')\n",
        "        else:\n",
        "            AD_status.append('outside_AD')\n",
        "\n",
        "    # Create DataFrame with index from x_test and the respective status\n",
        "    df = pd.DataFrame(AD_status, index=x_te.index, columns=['AD_status'])\n",
        "    return df\n",
        "test_ad = nearest_neighbor_AD_predict(x_te, x_deepra, 3, z=0.5)\n",
        "test_ad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWIObVQD06R6"
      },
      "outputs": [],
      "source": [
        "#Output\n",
        "DeepRA_AD = pd.concat([y_predict_deepra_class, test_ad],axis=1)\n",
        "DeepRA_AD.to_csv('y_predict_DeepRA_nss_ad.csv')\n",
        "DeepRA_AD"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
